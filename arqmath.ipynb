{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARQMath\n",
    "\n",
    "- https://www.cs.rit.edu/~dprl/ARQMath/\n",
    "- https://www.cs.rit.edu/~dprl/ARQMath/Task1-answers.html\n",
    "- https://httpd.test.gipp.com/qa-pair.csv\n",
    "- https://github.com/deepset-ai/FARM/blob/master/examples/passage_ranking.py\n",
    "\n",
    "### Requirements\n",
    "\n",
    "```\n",
    "pandas\n",
    "tqdm\n",
    "farm==0.4.2\n",
    "transformers\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import json\n",
    "import pickle\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "from sklearn.model_selection import KFold, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: nvidia-smi: command not found\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\" # check with nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "from farm.data_handler.data_silo import DataSilo\n",
    "from farm.data_handler.processor import RegressionProcessor, TextPairClassificationProcessor\n",
    "from farm.experiment import initialize_optimizer\n",
    "from farm.infer import Inferencer\n",
    "from farm.modeling.adaptive_model import AdaptiveModel\n",
    "from farm.modeling.language_model import LanguageModel\n",
    "from farm.modeling.prediction_head import RegressionHead, TextClassificationHead\n",
    "from farm.modeling.tokenization import Tokenizer\n",
    "from farm.train import Trainer\n",
    "from farm.utils import set_all_seeds, MLFlowLogger, initialize_device_settings, reformat_msmarco_train, reformat_msmarco_dev, write_msmarco_results\n",
    "from farm.evaluation.msmarco_passage_farm import msmarco_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
    "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "    level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/data/repo/acl-anthology/environments\n",
      "Environment detected: local_mac (in default.yml)\n"
     ]
    }
   ],
   "source": [
    "from experiments.environment import get_env\n",
    "env = get_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_b</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>What are gradients and how would I use them?\\n...</td>\n",
       "      <td>The ∇ (pronounced \"del\") is an operator, more ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>How would you describe calculus in simple term...</td>\n",
       "      <td>There came a time in mathematics when people e...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>How would you describe calculus in simple term...</td>\n",
       "      <td>One of the greatest achievements of human civi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>How would you describe calculus in simple term...</td>\n",
       "      <td>Calculus is basically a way of calculating rat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>How would you describe calculus in simple term...</td>\n",
       "      <td>Calculus is a field which deals with two seemi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  What are gradients and how would I use them?\\n...   \n",
       "1  How would you describe calculus in simple term...   \n",
       "2  How would you describe calculus in simple term...   \n",
       "3  How would you describe calculus in simple term...   \n",
       "4  How would you describe calculus in simple term...   \n",
       "\n",
       "                                              text_b  label  \n",
       "0  The ∇ (pronounced \"del\") is an operator, more ...      1  \n",
       "1  There came a time in mathematics when people e...      1  \n",
       "2  One of the greatest achievements of human civi...      0  \n",
       "3  Calculus is basically a way of calculating rat...      0  \n",
       "4  Calculus is a field which deals with two seemi...      0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert input to FARM TSV format: [text, text_b, label]\n",
    "df = pd.read_csv(os.path.join(env['datasets_dir'], 'arqmath', 'qa-pair.csv'))\n",
    "\n",
    "label_col = 'label'\n",
    "df[label_col] = df['rel'].astype(int)\n",
    "df = df.rename(columns=dict(q='text', a='text_b')).drop(columns=['qID', 'aID', 'rel'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(n=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 4\n",
    "kf = StratifiedKFold(n_splits=n_splits, random_state=0, shuffle=True)\n",
    "\n",
    "# Stratified K-Folds cross-validator\n",
    "for k, (train_index, test_index) in enumerate(kf.split(df.index.tolist(), df[label_col].values.tolist()), 1):\n",
    "    split_train_df = df.iloc[train_index]\n",
    "    split_test_df = df.iloc[test_index]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 374; Test: 126\n"
     ]
    }
   ],
   "source": [
    "train_df = split_train_df\n",
    "test_df = split_test_df\n",
    "\n",
    "print(f'Train: {len(train_df)}; Test: {len(test_df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to disk\n",
    "train_df.to_csv(os.path.join(env['datasets_dir'], 'arqmath', 'train.tsv'), sep='\\t', index=False)\n",
    "test_df.to_csv(os.path.join(env['datasets_dir'], 'arqmath', 'test.tsv'), sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/11/2020 17:13:33 - INFO - farm.utils -   device: cpu n_gpu: 0, distributed training: False, automatic mixed precision training: None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ngenerate_data = False\\ndata_dir = Path(\"../data/msmarco_passage\")\\npredictions_raw_filename = \"predictions_raw.txt\"\\npredictions_filename = \"predictions.txt\"\\ntrain_source_filename = \"triples.train.1m.tsv\"\\nqrels_filename = \"qrels.dev.tsv\"\\nqueries_filename = \"queries.dev.tsv\"\\npassages_filename = \"collection.tsv\"\\ntop1000_filename = \"top1000.dev\"\\n\\n# 0. Preprocess and save MSMarco data in a format that can be ingested by FARM models. Only needs to be done once!\\n# The final format is a tsv file with 3 columns (text, text_b and label)\\nif generate_data:\\n    reformat_msmarco_train(data_dir / train_source_filename,\\n                           data_dir / train_filename)\\n    reformat_msmarco_dev(data_dir / queries_filename,\\n                         data_dir / passages_filename,\\n                         data_dir / qrels_filename,\\n                         data_dir / top1000_filename,\\n                         data_dir / dev_filename)\\n\\n'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##########################\n",
    "########## Settings\n",
    "##########################\n",
    "set_all_seeds(seed=42)\n",
    "device, n_gpu = initialize_device_settings(use_cuda=torch.cuda.is_available())\n",
    "n_epochs = 2\n",
    "batch_size = 64\n",
    "evaluate_every = 500\n",
    "lang_model = \"bert-base-cased\"\n",
    "lang_model_path = os.path.join(env['bert_dir'], lang_model)\n",
    "label_list = [\"0\", \"1\"]\n",
    "\n",
    "data_dir = Path(os.path.join(env['datasets_dir'], 'arqmath'))\n",
    "#train_filename = \"train.tsv\"\n",
    "train_filename = 'train.tsv'\n",
    "\n",
    "#dev_filename = \"dev_200k.tsv\"\n",
    "dev_filename = None #'qa-pair.csv'\n",
    "test_filename = 'test.tsv'\n",
    "\n",
    "# The source data can be found here https://github.com/microsoft/MSMARCO-Passage-Ranking\n",
    "\"\"\"\n",
    "generate_data = False\n",
    "data_dir = Path(\"../data/msmarco_passage\")\n",
    "predictions_raw_filename = \"predictions_raw.txt\"\n",
    "predictions_filename = \"predictions.txt\"\n",
    "train_source_filename = \"triples.train.1m.tsv\"\n",
    "qrels_filename = \"qrels.dev.tsv\"\n",
    "queries_filename = \"queries.dev.tsv\"\n",
    "passages_filename = \"collection.tsv\"\n",
    "top1000_filename = \"top1000.dev\"\n",
    "\n",
    "# 0. Preprocess and save MSMarco data in a format that can be ingested by FARM models. Only needs to be done once!\n",
    "# The final format is a tsv file with 3 columns (text, text_b and label)\n",
    "if generate_data:\n",
    "    reformat_msmarco_train(data_dir / train_source_filename,\n",
    "                           data_dir / train_filename)\n",
    "    reformat_msmarco_dev(data_dir / queries_filename,\n",
    "                         data_dir / passages_filename,\n",
    "                         data_dir / qrels_filename,\n",
    "                         data_dir / top1000_filename,\n",
    "                         data_dir / dev_filename)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/11/2020 17:14:26 - INFO - farm.modeling.tokenization -   Loading tokenizer of type 'BertTokenizer'\n",
      "04/11/2020 17:14:26 - INFO - transformers.tokenization_utils -   Model name '/Volumes/data/repo/data/bert/bert-base-cased' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming '/Volumes/data/repo/data/bert/bert-base-cased' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "04/11/2020 17:14:26 - INFO - transformers.tokenization_utils -   Didn't find file /Volumes/data/repo/data/bert/bert-base-cased/added_tokens.json. We won't load it.\n",
      "04/11/2020 17:14:26 - INFO - transformers.tokenization_utils -   Didn't find file /Volumes/data/repo/data/bert/bert-base-cased/special_tokens_map.json. We won't load it.\n",
      "04/11/2020 17:14:26 - INFO - transformers.tokenization_utils -   Didn't find file /Volumes/data/repo/data/bert/bert-base-cased/tokenizer_config.json. We won't load it.\n",
      "04/11/2020 17:14:26 - INFO - transformers.tokenization_utils -   loading file /Volumes/data/repo/data/bert/bert-base-cased/vocab.txt\n",
      "04/11/2020 17:14:26 - INFO - transformers.tokenization_utils -   loading file None\n",
      "04/11/2020 17:14:26 - INFO - transformers.tokenization_utils -   loading file None\n",
      "04/11/2020 17:14:26 - INFO - transformers.tokenization_utils -   loading file None\n",
      "04/11/2020 17:14:26 - INFO - farm.data_handler.processor -   Initialized processor without tasks. Supply `metric` and `label_list` to the constructor for using the default task or add a custom task later via processor.add_task()\n"
     ]
    }
   ],
   "source": [
    "# 1.Create a tokenizer\n",
    "tokenizer = Tokenizer.load(\n",
    "    pretrained_model_name_or_path=lang_model_path,\n",
    "    do_lower_case=False)\n",
    "\n",
    "# 2. Create a DataProcessor that handles all the conversion from raw text into a pytorch Dataset\n",
    "#    Evaluation during training will be performed on a slice of the train set\n",
    "#    We will be using the msmarco dev set as our final evaluation set\n",
    "processor = TextPairClassificationProcessor(tokenizer=tokenizer,\n",
    "                                            label_list=label_list,\n",
    "                                            train_filename=train_filename,\n",
    "                                            test_filename=test_filename,\n",
    "                                            #dev_split=0.001,\n",
    "                                            dev_split=0.0,\n",
    "                                            max_seq_len=128,\n",
    "                                            data_dir=data_dir,\n",
    "                                            delimiter=\"\\t\")\n",
    "processor.add_task(name='text_classification', \n",
    "                   metric='seq_f1', \n",
    "                   label_list=label_list, \n",
    "                   label_column_name=label_col,\n",
    "                   task_type='classification')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/11/2020 17:14:26 - INFO - farm.data_handler.data_silo -   \n",
      "Loading data into the data silo ... \n",
      "              ______\n",
      "               |o  |   !\n",
      "   __          |:`_|---'-.\n",
      "  |__|______.-/ _ \\-----.|       \n",
      " (o)(o)------'\\ _ /     ( )      \n",
      " \n",
      "04/11/2020 17:14:26 - INFO - farm.data_handler.data_silo -   Loading train set from: /Volumes/data/repo/data/arqmath/train.tsv \n",
      "04/11/2020 17:14:26 - INFO - farm.data_handler.data_silo -   Got ya 7 parallel workers to convert 374 dictionaries to pytorch datasets (chunksize = 11)...\n",
      "04/11/2020 17:14:26 - INFO - farm.data_handler.data_silo -    0    0    0    0    0    0    0 \n",
      "04/11/2020 17:14:26 - INFO - farm.data_handler.data_silo -   /|\\  /w\\  /w\\  /w\\  /w\\  /w\\  /w\\\n",
      "04/11/2020 17:14:26 - INFO - farm.data_handler.data_silo -   /'\\  /'\\  /'\\  /'\\  /'\\  / \\  /'\\\n",
      "04/11/2020 17:14:26 - INFO - farm.data_handler.data_silo -               \n",
      "Preprocessing Dataset /Volumes/data/repo/data/arqmath/train.tsv:   0%|          | 0/374 [00:00<?, ? Dicts/s]04/11/2020 17:14:26 - INFO - farm.data_handler.processor -   *** Show 2 random examples ***\n",
      "04/11/2020 17:14:26 - INFO - farm.data_handler.processor -   \n",
      "\n",
      "      .--.        _____                       _      \n",
      "    .'_\\/_'.     / ____|                     | |     \n",
      "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
      "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
      "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
      "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
      "   (/\\||/                             |_|           \n",
      "______\\||/___________________________________________                     \n",
      "\n",
      "ID: train-10-0\n",
      "Clear Text: \n",
      " \ttext: Given:Let f:[a,b] \\to R, an integrable function on [a,b] such that \\int_a^x f(t) dt\\ge 0 for all x\\in [a,b] Prove: f(t)\\ge 0\n",
      " Given:Let f:[a,b] \\to R, an integrable function on [a,b] such that \\int_a^x f(t) dt\\ge 0 for all x\\in [a,b]  Prove the following or give an opposite example/disprove: f(t)\\ge 0  I'm having difficulties figuring out what I could use to prove this. I was thinking maybe the fundamental theorem of integral calculus since it's given in the form right away. \n",
      " \ttext_b: If $f$ is not continuous take f(a)=-1, f(x)=0, x\\neq a \n",
      " \ttext_classification_label: 0\n",
      "Tokenized: \n",
      " \ttokens: ['Given', ':', 'Let', 'f', ':', '[', 'a', ',', 'b', ']', '\\\\', 'to', 'R', ',', 'an', 'in', '##te', '##gra', '##ble', 'function', 'on', '[', 'a', ',', 'b', ']', 'such', 'that', '\\\\', 'in', '##t', '_', 'a', '^', 'x', 'f', '(', 't', ')', 'd', '##t', '\\\\', 'g', '##e', '0', 'for', 'all', 'x', '\\\\', 'in', '[', 'a', ',', 'b', ']', 'Pro', '##ve', ':', 'f', '(', 't', ')', '\\\\', 'g', '##e', '0', 'Given', ':', 'Let', 'f', ':', '[', 'a', ',', 'b', ']', '\\\\', 'to', 'R', ',', 'an', 'in', '##te', '##gra', '##ble', 'function', 'on', '[', 'a', ',', 'b', ']', 'such', 'that', '\\\\', 'in', '##t']\n",
      " \ttokens_b: ['If', '$', 'f', '$', 'is', 'not', 'continuous', 'take', 'f', '(', 'a', ')', '=', '-', '1', ',', 'f', '(', 'x', ')', '=', '0', ',', 'x', '\\\\', 'ne', '##q', 'a']\n",
      "Features: \n",
      " \tinput_ids: [101, 10470, 131, 2421, 175, 131, 164, 170, 117, 171, 166, 165, 1106, 155, 117, 1126, 1107, 1566, 14867, 2165, 3053, 1113, 164, 170, 117, 171, 166, 1216, 1115, 165, 1107, 1204, 168, 170, 167, 193, 175, 113, 189, 114, 173, 1204, 165, 176, 1162, 121, 1111, 1155, 193, 165, 1107, 164, 170, 117, 171, 166, 5096, 2707, 131, 175, 113, 189, 114, 165, 176, 1162, 121, 10470, 131, 2421, 175, 131, 164, 170, 117, 171, 166, 165, 1106, 155, 117, 1126, 1107, 1566, 14867, 2165, 3053, 1113, 164, 170, 117, 171, 166, 1216, 1115, 165, 1107, 1204, 102, 1409, 109, 175, 109, 1110, 1136, 6803, 1321, 175, 113, 170, 114, 134, 118, 122, 117, 175, 113, 193, 114, 134, 121, 117, 193, 165, 24928, 4426, 170, 102]\n",
      " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      " \ttext_classification_label_ids: [0]\n",
      "_____________________________________________________\n",
      "04/11/2020 17:14:26 - INFO - farm.data_handler.processor -   \n",
      "\n",
      "      .--.        _____                       _      \n",
      "    .'_\\/_'.     / ____|                     | |     \n",
      "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
      "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
      "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
      "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
      "   (/\\||/                             |_|           \n",
      "______\\||/___________________________________________                     \n",
      "\n",
      "ID: train-5-0\n",
      "Clear Text: \n",
      " \ttext: Deriving an inequality for Riemann sums\n",
      "\n",
      "I am reading a proof of the MVT for Integrals  and the following inequality seems a bit non-intuitive and I'm not certain as to how it is derived (although the writer has seemingly indicated its derivation is from the fact that m\\le f(x_i)\\le M, \\forall x_i \\in [a,b] and m,M \\in [a,b]):  since m \\le f(x_i ^*) \\le M for all x_i ^* \\in [a, b], we have \\lim \\limits _{n \\to \\infty} \\frac {b-a} n \\sum \\limits _{i=1} ^n m \\le \\lim \\limits _{n \\to \\infty} \\frac {b-a} n \\sum \\limits _{i=1} ^n f(x_i ^*) \\le \\lim \\limits _{n \\to \\infty} \\frac {b-a} n \\sum \\limits _{i=1} ^n M  The furthest I got in attempting to derive this inequality was by cancelling out \\lim \\limits _{n \\to \\infty} \\frac{b-a}{n} (I'm not sure whether this is valid or not) then trying to prove \\sum \\limits _{i=1}^n m \\le \\sum \\limits _{i=1}^n f(x_i) \\le \\sum \\limits _{i=1}^n M, which itself does not look true.  \n",
      " \ttext_b: This follows from the subsequent fact: Suppose (a_n)_n, (b_n)_n are real sequences converging to a,b respectively and a_n \\leq b_n. Then a\\leq b. So you have to understand why all the limits in the above calculation exist (e.g. the left most limit exists because the $n$ actually cancels with the sum.) \n",
      " \ttext_classification_label: 0\n",
      "Tokenized: \n",
      " \ttokens: ['Der', '##iving', 'an', 'inequality', 'for', 'R', '##ie', '##mann', 'sums', 'I', 'am', 'reading', 'a', 'proof', 'of', 'the', 'MV', '##T', 'for', 'In', '##te', '##gra', '##ls', 'and', 'the', 'following', 'inequality', 'seems', 'a', 'bit', 'non', '-', 'in', '##tu', '##itive', 'and', 'I', \"'\", 'm', 'not', 'certain', 'as', 'to', 'how', 'it', 'is', 'derived', '(', 'although', 'the', 'writer', 'has', 'seemingly', 'indicated', 'its', 'der', '##ivation', 'is', 'from', 'the', 'fact', 'that', 'm']\n",
      " \ttokens_b: ['This', 'follows', 'from', 'the', 'subsequent', 'fact', ':', 'Su', '##pp', '##ose', '(', 'a', '_', 'n', ')', '_', 'n', ',', '(', 'b', '_', 'n', ')', '_', 'n', 'are', 'real', 'sequences', 'con', '##ver', '##ging', 'to', 'a', ',', 'b', 'respectively', 'and', 'a', '_', 'n', '\\\\', 'le', '##q', 'b', '_', 'n', '.', 'Then', 'a', '\\\\', 'le', '##q', 'b', '.', 'So', 'you', 'have', 'to', 'understand', 'why', 'all', 'the']\n",
      "Features: \n",
      " \tinput_ids: [101, 9682, 21877, 1126, 18610, 1111, 155, 1663, 4119, 22958, 146, 1821, 3455, 170, 6777, 1104, 1103, 23061, 1942, 1111, 1130, 1566, 14867, 3447, 1105, 1103, 1378, 18610, 3093, 170, 2113, 1664, 118, 1107, 7926, 8588, 1105, 146, 112, 182, 1136, 2218, 1112, 1106, 1293, 1122, 1110, 4408, 113, 1780, 1103, 2432, 1144, 9321, 4668, 1157, 4167, 16617, 1110, 1121, 1103, 1864, 1115, 182, 102, 1188, 3226, 1121, 1103, 4194, 1864, 131, 15463, 8661, 6787, 113, 170, 168, 183, 114, 168, 183, 117, 113, 171, 168, 183, 114, 168, 183, 1132, 1842, 10028, 14255, 4121, 3375, 1106, 170, 117, 171, 3569, 1105, 170, 168, 183, 165, 5837, 4426, 171, 168, 183, 119, 1599, 170, 165, 5837, 4426, 171, 119, 1573, 1128, 1138, 1106, 2437, 1725, 1155, 1103, 102]\n",
      " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      " \ttext_classification_label_ids: [0]\n",
      "_____________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing Dataset /Volumes/data/repo/data/arqmath/train.tsv: 100%|██████████| 374/374 [00:01<00:00, 370.46 Dicts/s]\n",
      "04/11/2020 17:14:27 - INFO - farm.data_handler.data_silo -   No dev set is being loaded\n",
      "04/11/2020 17:14:27 - INFO - farm.data_handler.data_silo -   Loading test set from: /Volumes/data/repo/data/arqmath/test.tsv\n",
      "04/11/2020 17:14:27 - INFO - farm.data_handler.data_silo -   Got ya 7 parallel workers to convert 126 dictionaries to pytorch datasets (chunksize = 4)...\n",
      "04/11/2020 17:14:27 - INFO - farm.data_handler.data_silo -    0    0    0    0    0    0    0 \n",
      "04/11/2020 17:14:27 - INFO - farm.data_handler.data_silo -   /|\\  /w\\  /|\\  /|\\  /|\\  /|\\  /w\\\n",
      "04/11/2020 17:14:27 - INFO - farm.data_handler.data_silo -   /'\\  / \\  /'\\  /'\\  /'\\  /'\\  / \\\n",
      "04/11/2020 17:14:27 - INFO - farm.data_handler.data_silo -               \n",
      "Preprocessing Dataset /Volumes/data/repo/data/arqmath/test.tsv:   0%|          | 0/126 [00:00<?, ? Dicts/s]04/11/2020 17:14:28 - INFO - farm.data_handler.processor -   *** Show 2 random examples ***\n",
      "04/11/2020 17:14:28 - INFO - farm.data_handler.processor -   \n",
      "\n",
      "      .--.        _____                       _      \n",
      "    .'_\\/_'.     / ____|                     | |     \n",
      "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
      "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
      "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
      "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
      "   (/\\||/                             |_|           \n",
      "______\\||/___________________________________________                     \n",
      "\n",
      "ID: train-2-0\n",
      "Clear Text: \n",
      " \ttext: roots of equation  e^{2x}\\sin (2x) +7=0\n",
      "Let a,b,c be roots of equation  e^{2x}\\sin2x -7=0 then roots of equation  e^{2x}\\sin2x +7=0 lies between p and q where  Both p and q \\in(a, b) Both p and q \\in(b, c) p \\in (a, b) and q \\in(b, c) p \\in (a, b) and q \\notin(b, c)  my attempt: I plotted graphs of \\sin2x,  e^{-2x}, -e^{-2x}. But I have doubt further from here \n",
      " \ttext_b: Given the location of the roots (and assuming they are consecutive and a<b<c), you have f(x)>0 in (a,b) and f(x)<0 in (b,c), or conversely. Now you are looking for the solutions of f(x)=14, which are both in (a,b) or both in (b,c) (you cannot tell). \n",
      " \ttext_classification_label: 0\n",
      "Tokenized: \n",
      " \ttokens: ['roots', 'of', 'equation', 'e', '^', '{', '2', '##x', '}', '\\\\', 'sin', '(', '2', '##x', ')', '+', '7', '=', '0', 'Let', 'a', ',', 'b', ',', 'c', 'be', 'roots', 'of', 'equation', 'e', '^', '{', '2', '##x', '}', '\\\\', 'sin', '##2', '##x', '-', '7', '=', '0', 'then', 'roots', 'of', 'equation', 'e', '^', '{', '2', '##x', '}', '\\\\', 'sin', '##2', '##x', '+', '7', '=', '0', 'lies', 'between']\n",
      " \ttokens_b: ['Given', 'the', 'location', 'of', 'the', 'roots', '(', 'and', 'assuming', 'they', 'are', 'consecutive', 'and', 'a', '<', 'b', '<', 'c', ')', ',', 'you', 'have', 'f', '(', 'x', ')', '>', '0', 'in', '(', 'a', ',', 'b', ')', 'and', 'f', '(', 'x', ')', '<', '0', 'in', '(', 'b', ',', 'c', ')', ',', 'or', 'con', '##verse', '##ly', '.', 'Now', 'you', 'are', 'looking', 'for', 'the', 'solutions', 'of', 'f']\n",
      "Features: \n",
      " \tinput_ids: [101, 6176, 1104, 8381, 174, 167, 196, 123, 1775, 198, 165, 11850, 113, 123, 1775, 114, 116, 128, 134, 121, 2421, 170, 117, 171, 117, 172, 1129, 6176, 1104, 8381, 174, 167, 196, 123, 1775, 198, 165, 11850, 1477, 1775, 118, 128, 134, 121, 1173, 6176, 1104, 8381, 174, 167, 196, 123, 1775, 198, 165, 11850, 1477, 1775, 116, 128, 134, 121, 2887, 1206, 102, 10470, 1103, 2450, 1104, 1103, 6176, 113, 1105, 11577, 1152, 1132, 4776, 1105, 170, 133, 171, 133, 172, 114, 117, 1128, 1138, 175, 113, 193, 114, 135, 121, 1107, 113, 170, 117, 171, 114, 1105, 175, 113, 193, 114, 133, 121, 1107, 113, 171, 117, 172, 114, 117, 1137, 14255, 10840, 1193, 119, 1986, 1128, 1132, 1702, 1111, 1103, 7995, 1104, 175, 102]\n",
      " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      " \ttext_classification_label_ids: [0]\n",
      "_____________________________________________________\n",
      "04/11/2020 17:14:28 - INFO - farm.data_handler.processor -   \n",
      "\n",
      "      .--.        _____                       _      \n",
      "    .'_\\/_'.     / ____|                     | |     \n",
      "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
      "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
      "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
      "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
      "   (/\\||/                             |_|           \n",
      "______\\||/___________________________________________                     \n",
      "\n",
      "ID: train-2-0\n",
      "Clear Text: \n",
      " \ttext: roots of equation  e^{2x}\\sin (2x) +7=0\n",
      "Let a,b,c be roots of equation  e^{2x}\\sin2x -7=0 then roots of equation  e^{2x}\\sin2x +7=0 lies between p and q where  Both p and q \\in(a, b) Both p and q \\in(b, c) p \\in (a, b) and q \\in(b, c) p \\in (a, b) and q \\notin(b, c)  my attempt: I plotted graphs of \\sin2x,  e^{-2x}, -e^{-2x}. But I have doubt further from here \n",
      " \ttext_b: Given the location of the roots (and assuming they are consecutive and a<b<c), you have f(x)>0 in (a,b) and f(x)<0 in (b,c), or conversely. Now you are looking for the solutions of f(x)=14, which are both in (a,b) or both in (b,c) (you cannot tell). \n",
      " \ttext_classification_label: 0\n",
      "Tokenized: \n",
      " \ttokens: ['roots', 'of', 'equation', 'e', '^', '{', '2', '##x', '}', '\\\\', 'sin', '(', '2', '##x', ')', '+', '7', '=', '0', 'Let', 'a', ',', 'b', ',', 'c', 'be', 'roots', 'of', 'equation', 'e', '^', '{', '2', '##x', '}', '\\\\', 'sin', '##2', '##x', '-', '7', '=', '0', 'then', 'roots', 'of', 'equation', 'e', '^', '{', '2', '##x', '}', '\\\\', 'sin', '##2', '##x', '+', '7', '=', '0', 'lies', 'between']\n",
      " \ttokens_b: ['Given', 'the', 'location', 'of', 'the', 'roots', '(', 'and', 'assuming', 'they', 'are', 'consecutive', 'and', 'a', '<', 'b', '<', 'c', ')', ',', 'you', 'have', 'f', '(', 'x', ')', '>', '0', 'in', '(', 'a', ',', 'b', ')', 'and', 'f', '(', 'x', ')', '<', '0', 'in', '(', 'b', ',', 'c', ')', ',', 'or', 'con', '##verse', '##ly', '.', 'Now', 'you', 'are', 'looking', 'for', 'the', 'solutions', 'of', 'f']\n",
      "Features: \n",
      " \tinput_ids: [101, 6176, 1104, 8381, 174, 167, 196, 123, 1775, 198, 165, 11850, 113, 123, 1775, 114, 116, 128, 134, 121, 2421, 170, 117, 171, 117, 172, 1129, 6176, 1104, 8381, 174, 167, 196, 123, 1775, 198, 165, 11850, 1477, 1775, 118, 128, 134, 121, 1173, 6176, 1104, 8381, 174, 167, 196, 123, 1775, 198, 165, 11850, 1477, 1775, 116, 128, 134, 121, 2887, 1206, 102, 10470, 1103, 2450, 1104, 1103, 6176, 113, 1105, 11577, 1152, 1132, 4776, 1105, 170, 133, 171, 133, 172, 114, 117, 1128, 1138, 175, 113, 193, 114, 135, 121, 1107, 113, 170, 117, 171, 114, 1105, 175, 113, 193, 114, 133, 121, 1107, 113, 171, 117, 172, 114, 117, 1137, 14255, 10840, 1193, 119, 1986, 1128, 1132, 1702, 1111, 1103, 7995, 1104, 175, 102]\n",
      " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      " \ttext_classification_label_ids: [0]\n",
      "_____________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing Dataset /Volumes/data/repo/data/arqmath/test.tsv: 100%|██████████| 126/126 [00:00<00:00, 264.56 Dicts/s]\n",
      "04/11/2020 17:14:28 - INFO - farm.data_handler.data_silo -   Examples in train: 374\n",
      "04/11/2020 17:14:28 - INFO - farm.data_handler.data_silo -   Examples in dev  : 0\n",
      "04/11/2020 17:14:28 - INFO - farm.data_handler.data_silo -   Examples in test : 126\n",
      "04/11/2020 17:14:28 - INFO - farm.data_handler.data_silo -   \n",
      "04/11/2020 17:14:28 - INFO - farm.data_handler.data_silo -   Longest sequence length observed after clipping:     128\n",
      "04/11/2020 17:14:28 - INFO - farm.data_handler.data_silo -   Average sequence length after clipping: 127.27540106951872\n",
      "04/11/2020 17:14:28 - INFO - farm.data_handler.data_silo -   Proportion clipped:      0.9705882352941176\n",
      "04/11/2020 17:14:28 - INFO - farm.data_handler.data_silo -   [Farmer's Tip] 97.1% of your samples got cut down to 128 tokens. Consider increasing max_seq_len. This will lead to higher memory consumption but is likely to improve your model performance\n"
     ]
    }
   ],
   "source": [
    "# 3. Create a DataSilo that loads several datasets (train/dev/test), provides DataLoaders for them and calculates a few descriptive statistics of our datasets\n",
    "data_silo = DataSilo(\n",
    "    processor=processor,\n",
    "    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/11/2020 17:14:39 - INFO - transformers.modeling_utils -   loading weights file /Volumes/data/repo/data/bert/bert-base-cased/pytorch_model.bin\n",
      "04/11/2020 17:14:41 - WARNING - farm.modeling.language_model -   Could not automatically detect from language model name what language it is. \n",
      "\t We guess it's an *ENGLISH* model ... \n",
      "\t If not: Init the language model by supplying the 'language' param.\n",
      "04/11/2020 17:14:41 - INFO - farm.modeling.prediction_head -   Prediction head initialized with size [768, 2]\n",
      "04/11/2020 17:14:41 - INFO - farm.modeling.prediction_head -   Using class weights for task 'text_classification': [0.7230769230769231, 1.6206896551724137]\n",
      "04/11/2020 17:14:41 - INFO - farm.modeling.optimization -   Loading optimizer `TransformersAdamW`: '{'correct_bias': False, 'weight_decay': 0.01, 'lr': 1e-05}'\n",
      "04/11/2020 17:14:41 - INFO - farm.modeling.optimization -   Using scheduler 'get_linear_schedule_with_warmup'\n",
      "04/11/2020 17:14:41 - INFO - farm.modeling.optimization -   Loading schedule `get_linear_schedule_with_warmup`: '{'num_warmup_steps': 1.2000000000000002, 'num_training_steps': 12}'\n"
     ]
    }
   ],
   "source": [
    "# 4. Create an AdaptiveModel\n",
    "# a) which consists of a pretrained language model as a basis\n",
    "language_model = LanguageModel.load(lang_model_path)\n",
    "# b) and a prediction head on top that is suited for our task\n",
    "prediction_head = TextClassificationHead(num_labels=len(label_list),\n",
    "                                         class_weights=data_silo.calculate_class_weights(\n",
    "                                             task_name=\"text_classification\"),\n",
    "                                         )\n",
    "\n",
    "model = AdaptiveModel(\n",
    "    language_model=language_model,\n",
    "    prediction_heads=[prediction_head],\n",
    "    embeds_dropout_prob=0.1,\n",
    "    lm_output_types=[\"per_sequence_continuous\"],\n",
    "    device=device)\n",
    "\n",
    "# 5. Create an optimizer\n",
    "model, optimizer, lr_schedule = initialize_optimizer(\n",
    "    model=model,\n",
    "    learning_rate=1e-5,\n",
    "    device=device,\n",
    "    n_batches=len(data_silo.loaders[\"train\"]),\n",
    "    n_epochs=n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Feed everything to the Trainer, which keeps care of growing our model into powerful plant and evaluates it from time to time\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    data_silo=data_silo,\n",
    "    epochs=n_epochs,\n",
    "    n_gpu=n_gpu,\n",
    "    lr_schedule=lr_schedule,\n",
    "    evaluate_every=evaluate_every,\n",
    "    device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/11/2020 17:15:19 - INFO - farm.train -   \n",
      " \n",
      "\n",
      "          &&& &&  & &&             _____                   _             \n",
      "      && &\\/&\\|& ()|/ @, &&       / ____|                 (_)            \n",
      "      &\\/(/&/&||/& /_/)_&/_&     | |  __ _ __ _____      ___ _ __   __ _ \n",
      "   &() &\\/&|()|/&\\/ '%\" & ()     | | |_ | '__/ _ \\ \\ /\\ / / | '_ \\ / _` |\n",
      "  &_\\_&&_\\ |& |&&/&__%_/_& &&    | |__| | | | (_) \\ V  V /| | | | | (_| |\n",
      "&&   && & &| &| /& & % ()& /&&    \\_____|_|  \\___/ \\_/\\_/ |_|_| |_|\\__, |\n",
      " ()&_---()&\\&\\|&&-&&--%---()~                                       __/ |\n",
      "     &&     \\|||                                                   |___/\n",
      "             |||\n",
      "             |||\n",
      "             |||\n",
      "       , -=-~  .-^- _\n",
      "              `\n",
      "\n",
      "Train epoch 0/2 (Cur. train loss: 0.7168):  83%|████████▎ | 5/6 [02:11<00:25, 25.67s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-46e6da0cc7ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 7. Let it grow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/acl-anthology/lib/python3.7/site-packages/farm/train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    244\u001b[0m                 \u001b[0mper_sample_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits_to_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward_propagate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mper_sample_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m                 \u001b[0;31m# Perform  evaluation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/acl-anthology/lib/python3.7/site-packages/farm/train.py\u001b[0m in \u001b[0;36mbackward_propagate\u001b[0;34m(self, loss, step)\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0mscaled_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_learning_rate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/acl-anthology/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/acl-anthology/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 7. Let it grow\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Hooray! You have a model. Store it:\n",
    "save_dir = Path(\"./output/arqmath/1\")\n",
    "\n",
    "model.save(save_dir)\n",
    "processor.save(save_dir)\n",
    "\n",
    "# 9. Load it & harvest your fruits (Inference)\n",
    "#    Add your own text adapted to the dataset you provide\n",
    "model = Inferencer.load(save_dir, gpu=True, max_seq_len=128, batch_size=128)\n",
    "result = model.inference_from_file(data_dir / dev_filename)\n",
    "\n",
    "write_msmarco_results(result, save_dir / predictions_raw_filename)\n",
    "\n",
    "msmarco_evaluation(preds_file=save_dir / predictions_raw_filename,\n",
    "                   dev_file=data_dir / dev_filename,\n",
    "                   qrels_file=data_dir / qrels_filename,\n",
    "                   output_file=save_dir / predictions_filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
